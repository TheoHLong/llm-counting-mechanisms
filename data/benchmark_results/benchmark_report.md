# LLM Counting Task Benchmark Report
Generated on: 2025-06-01 21:31:51

## Overall Performance
- **meta-llama/Meta-Llama-3.1-8B-Instruct**: 31.90% accuracy
- **microsoft/phi-4**: 65.50% accuracy
- **Qwen/Qwen3-8B**: 40.00% accuracy

## Performance by Type
           meta-llama/Meta-Llama-3.1-8B-Instruct  microsoft/phi-4  Qwen/Qwen3-8B
type                                                                            
animal                                  0.393617         0.734043       0.457447
body_part                               0.509804         0.696078       0.392157
building                                0.151899         0.329114       0.253165
clothing                                0.375000         0.772727       0.590909
color                                   0.348315         0.719101       0.393258
emotion                                 0.404494         0.752809       0.471910
fruit                                   0.441860         0.941860       0.569767
sport                                   0.240964         0.638554       0.349398
tool                                    0.206522         0.608696       0.315217
vehicle                                 0.174419         0.534884       0.313953
weather                                 0.232143         0.482143       0.303571